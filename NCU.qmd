---
title: "Apprendre un langage de programmation à l'aide LLM"
subtitle: "Avec R"
author: "Elias Bouacida"
format: html
date: last-modified
lang: fr
date-format: long
---

# Question pour le projet

## Question 1

Description du projet / du dispositif proposé, des séquences pédagogiques et de sa chronologie
*
Objectifs et enjeux pour les étudiant.es ? Liens avec les compétences transversales ? Comment l'enseignement a-t-il été pensé ? Quelle est son originalité par rapport aux objectifs ?

Ce cours est une première tentative de repenser l'apprentissage, ici de la programmation, à l'heure des LLMs.
Le cours est construit sur un cours déjà existant d'initiation au langage de programmation R.
Le but de ce projet est d'apprendre à des étudiant.es qui n'ont *a priori* pas d'expérience de langage de programmation à coder dans le langage R grâce aux LLMs (aussi appelés IA géneratives).
Les LLMs rentrent rentrent dans la vie courante et sont amenés à rester.
Ils sont intéressants d'un point de vue pédagogique car ils permettent un apprentissage autonome et ils peuvent abaisser la barrière à l'entrée pour certaines pratiques, et notamment la programmation.
L'avantage d'utiliser des LLMs comme assistant de programmation est qu'il n'y a pas de pré-requis disciplinaire.

Pour les étudiants, ce cours vise à l'acquisition de multiples savoirs et compétences transversales.

- Apprendre aux étudiants que la programmation est abordable à l'heure des LLMs et que l'on peut rapidement et assez facilement faire des choses intéressantes.
- Apprendre aux étudiants l'usage raisonnée des LLMs : ceux-ci font des erreurs et il est important d'avoir un regard critique sur leurs résultats.
Il est important ici que les LLMs fassent des erreurs.
Cela permettra par la même occasion aux étudiants d'évaluer la qualité de leur action et d'exercer leur discernement.
- Il est clair que les étudiants utilisent déjà régulièrement des LLMs, mais l'expérience semble indiquer qu'ils n'ont pas un regard critique sur leur usage.
L'exemple de la programmation doit leur servir à acquérir un regard critique sur les LLMs et à questionner leurs réponses.
- Les LLMs sont un accélérateur d'apprentissage.
Ils devraient permettre aux étudiants de mener à bien des projets en programmation assez rapidement.
- Enfin, les étudiants pourront se familiariser avec quelques concepts simples de programmation et réfléchir à l'analyse de données.

Ce projet présente de mon point de vue trois pédagogies peu utilisée dans les cursus traditionnel :

1. Un apprentissage par essai/erreur. 
L'erreur est ici utilisé comme levier d'apprentissage et orchestrée pédagogiquement.
2. L'apprentissage par le faire (learning by doing, prompting même), plus que par la transmission.
3. L'IA générative est utilisée ici comme un partenaire d'apprentissage, et non comme un fournisseur de réponses toutes faites exactes.
Le but est bien de replacer celle-ci dans une place où elle est utile à l'apprentissage.

Question 2
Objectifs d'apprentissage et activités pédagogiques pour les atteindre
*
Répondre selon le schéma suivant : 

À la fin de cet EC, les étudiant.e.s seront capables de … 
Pour cela, ils/elles feront… 

Inclure la chronologie des séquences pédagogiques. 
Vous pouvez, par exemple, répondre selon le schéma : Séquence 1 : Objectif … Activités … 

## Objectifs d'apprentissage et séquences pédagogiques

### À la fin de cet EC, les étudiant.e.s seront capables de :

1. Analyser des données réelles en mobilisant R et un LLM de manière autonome
2. Formuler des requêtes efficaces à un LLM pour résoudre des problèmes de programmation
3. Évaluer critiquement et corriger les codes proposés par un LLM
4. Créer des fonctions personnalisées et organiser leur code de manière modulaire
5. Utilise un LLM comme partenaire de réflexion dans un projet d'analyse de données
6. Documenter et communiquer leurs analyses de manière reproductible

### Pour cela, ils/elles feront :

- Des analyses de données authentiques avec debugging collectif
- De la programmation par dialogue itératif avec des LLM
- Des projets collaboratifs intégrant code, analyse et communication
- De la réflexion métacognitive sur leurs stratégies d'apprentissage

---

## Chronologie des séquences pédagogiques

### Séquence 1 (3h) - Découverte et premiers dialogues

Objectif : Établir une première relation productive avec un LLM et comprendre les concepts de base de R

Activités :

- Introduction collective (30min) : Démonstration live d'interaction avec un LLM
- Premiers prompts guidés (45min) : "Calcule la moyenne de ces températures : 15, 18, 22, 16, 20"
- Exercice piégé collectif (45min) : Prompt vague → code défaillant → amélioration itérative
- Concepts émergents (30min) : Variables, types de données, assignation
- Journal de bord (30min) : Première entrée réflexive sur l'expérience

Production attendue : Premier code R fonctionnel + réflexion sur les prompts efficaces



### Séquence 2 (3h) - Vecteurs et fonctions de base

Objectif : Manipuler des collections de données et comprendre le concept de fonction

Activités :

- Récap et partage (20min) : Retours sur les devoirs, difficultés rencontrées
- Dataset piégé (60min) : Données météo avec NA cachés → prompts pour calculs statistiques
- Debugging collectif (40min) : "Pourquoi `mean(temperatures)` renvoie NA ?"
- Exploration fonctions built-in (60min) : `sum()`, `length()`, `min()`, `max()` via prompts
- Mini-projet individuel (40min) : Analyser des données de leur choix avec aide LLM

Production attendue : Analyse météo commentée + 3 fonctions maîtrisées


### Séquence 3 (3h) - Créer ses propres fonctions

Objectif : Concevoir et implémenter des fonctions personnalisées avec structures de contrôle

Activités :

- Challenge d'ouverture (30min) : "Créez une fonction qui dit si une personne peut voter"
- Atelier fonction collaborative (90min) : Construction collective d'une fonction de notation avec gestion d'erreurs
- Exercices de debugging (60min) : Codes buggés à corriger (boucles infinies, conditions mal écrites)
- Projet personnel (40min) : Chacun crée 2 fonctions utiles pour son domaine d'études

Production attendue : 3 fonctions personnalisées documentées + tests de validation

### Séquence 4 (3h) - Données tabulaires et visualisation

Objectif : Maîtriser les dataframes et créer des visualisations pertinentes

Activités :

- Dataset complexe commun (45min) : Données de ventes avec incohérences (casse, formats)
- Nettoyage collaboratif (60min) : Stratégies de prompting pour nettoyer les données
- Atelier ggplot2 (75min) : Du prompt basique aux graphiques sophistiqués
- Fonction graphique personnalisée (40min) : Créer sa fonction de visualisation type

Production attendue : Dashboard de 4 graphiques + fonction de visualisation réutilisable

### Séquence 5 (3h) - Projet personnel intégré

Objectif : Mener une analyse complète de A à Z de manière autonome

Activités :

- Choix et cadrage (30min) : Sélection dataset personnel + définition des questions
- Travail autonome supervisé (120min) : Analyse libre avec consultations individuelles
- Présentations courtes (50min) : 5min/étudiant + questions/suggestions des pairs

Production attendue : Analyse complète avec code, graphiques et interprétation


### Séquence 6 (3h) - Organisation et modularité

Objectif : Structurer son code et découvrir l'écosystème des packages

Activités :

- Refactoring collectif (45min) : Transformer un long script en modules organisés
- Exploration packages (60min) : dplyr, lubridate via prompts ciblés
- Gestion des erreurs (45min) : Packages manquants, conflits, chemins de fichiers
- Mini-package personnel (50min) : Organiser ses fonctions en scripts thématiques

Production attendue : Code organisé en modules + maîtrise de 3 packages

### Séquence 7 (3h) - Automatisation et rapports

Objectif : Automatiser des analyses répétitives et créer des rapports reproductibles

Activités :

- Traitement par lots (60min) : Analyser plusieurs fichiers CSV d'un coup
- Introduction R Markdown (60min) : Mélanger code, texte et graphiques
- Rapport paramétré (80min) : Créer un template d'analyse réutilisable
- Tests et validation (20min) : Vérifier la robustesse sur différents datasets

Production attendue : Rapport automatisé fonctionnel au format PDF



### Séquence 8 (3h) - Projet collaboratif final

Objectif : Intégrer toutes les compétences dans un projet d'équipe avec bonnes pratiques

Activités :

- Constitution équipes et répartition (30min) : 4 équipes, 4 angles d'analyse du même dataset
- Code review croisé (45min) : Analyser et améliorer le code d'une autre équipe
- Intégration collaborative (90min) : Faire fonctionner ensemble les analyses de toutes les équipes
- Présentation finale (35min) : Synthèse collective des résultats croisés

Production attendue : Analyse collaborative intégrée + code review documenté

## Logique de progression pédagogique

Phase 1 (Séquences 1-3) : Fondations
- Relation avec l'IA ✓ Concepts de base ✓ Autonomie technique

Phase 2 (Séquences 4-5) : Application 
- Projets personnels ✓ Analyses complètes ✓ Créativité

Phase 3 (Séquences 6-8) : Expertise
- Organisation ✓ Automatisation ✓ Collaboration

Cette progression spiralaire garantit que chaque concept est revisité avec une complexité croissante, permettant un ancrage solide des apprentissages tout en maintenant l'engagement par la variété des activités.

Question 3

Production(s) /réalisation(s) attendue(s) des étudiant.es

## Productions/réalisations attendues des étudiant.es

### Productions individuelles continues

#### 1. Journal de bord des interactions LLM (tout au long du semestre)

Format : Carnet numérique structuré (15-20 pages)  
Contenu :

- Évolution des prompts utilisés (exemples concrets)
- Erreurs rencontrées et stratégies de résolution
- Réflexions sur l'efficacité des différentes approches
- Auto-évaluation de la progression

Exemple d'entrée attendue :
```
Séance 3 - Création de fonction de notation
Prompt initial : "Fais une fonction pour les notes"
→ Échec : trop vague
Prompt amélioré : "Crée une fonction R qui convertit une note sur 20 
en mention (Insuffisant < 10, Passable 10-12, etc.)"
→ Succès mais bug sur les cas limites
Apprentissage : Toujours préciser les cas limites dans les prompts
```

#### 2. Portfolio de mini-projets (5 analyses, une par séance 2-6)

Format : Fichiers R commentés + interprétations (2-3 pages chacun)  
Exemples :

- Séance 2 : Analyse météorologique de leur région
- Séance 3 : Calculateur personnel (IMC, budget, etc.) avec fonctions
- Séance 4 : Dashboard de données socio-économiques
- Séance 5 : Analyse libre d'un sujet de leur choix
- Séance 6 : Refactoring d'un ancien projet en modules

#### 3. Bibliothèque de fonctions personnelles (évolutive)

Format : Scripts R documentés et organisés  
Contenu : Minimum 10 fonctions créées, testées et documentées  
Exemple :

```r
#' Calcule les statistiques descriptives complètes
#' @param donnees Vecteur numérique
#' @param arrondir Nombre de décimales (défaut: 2)
#' @return Liste avec moyenne, médiane, écart-type, etc.
stats_completes <- function(donnees, arrondir = 2) {
  # Code avec gestion d'erreurs...
}
```

### Productions collectives et collaboratives

#### 4. Projet final collaboratif (séance 8)

Format : Analyse multi-équipes d'un dataset complexe
Structure :

- 4 équipes, 4 approches du même jeu de données (ex: données COVID)

  - Équipe 1 : Évolution temporelle
  - Équipe 2 : Comparaisons géographiques
  - Équipe 3 : Facteurs socio-économiques
  - Équipe 4 : Modélisation prédictive simple

Livrables par équipe :

- Code R modulaire et commenté
- Rapport d'analyse (8-10 pages)
- Présentation orale (10 minutes)

Livrable collectif :

- Synthèse intégrée des 4 analyses
- Code unifié et compatible
- Recommandations communes

#### 5. Sessions de code review (séances 6-8)

Format : Évaluations croisées entre étudiants
Contenu :

- Analyse critique du code d'un pair
- Suggestions d'amélioration
- Tests de robustesse sur différents datasets
- Rapport de review (2-3 pages)


### Productions d'évaluation finale

#### 6. Rapport automatisé reproductible (séance 7)

Format : R Markdown générant un PDF
Spécifications techniques :

- Template paramétrable pour différents datasets
- Minimum 5 graphiques automatiques
- Statistiques descriptives complètes
- Interprétation automatique des résultats principaux

Exemple d'utilisation :

```r
# L'étudiant doit créer un rapport qui fonctionne avec :
generer_rapport("donnees_ventes_2023.csv", "Analyse des ventes 2023")
generer_rapport("donnees_sondage.csv", "Résultats du sondage")
```

#### 7. Soutenance individuelle (15 minutes)

Structure :

- Démonstration live (5 min) : Interaction avec LLM pour résoudre un problème inédit
- Présentation du portfolio (5 min) : Sélection de 3 réalisations significatives
- Questions/réponses (5 min) : Évaluation de la compréhension et de l'esprit critique



### Productions créatives et ouvertes

#### 8. Projet d'application disciplinaire (optionnel, bonus)

Format : Libre, adapté au domaine d'études de l'étudiant
Exemples :

- Psychologie : Analyse de données d'enquête avec visualisations
- Sociologie : Traitement de données qualitatives codées
- Économie : Modélisation de séries temporelles simples
- Sciences : Analyse de données expérimentales



### Critères de qualité transversaux

#### Excellence technique :

- Code fonctionnel et robuste
- Gestion appropriée des erreurs et cas particuliers
- Organisation claire et modulaire
- Documentation complète

#### Maîtrise de l'IA :

- Prompts précis et efficaces
- Validation critique des réponses
- Amélioration itérative des interactions
- Intégration fluide dans le workflow

#### Communication :

- Interprétation pertinente des résultats
- Visualisations claires et informatives
- Code lisible et bien commenté
- Présentation orale structurée

#### Réflexivité :

- Analyse de sa propre progression
- Identification des difficultés et solutions
- Transfert des apprentissages
- Esprit critique sur les outils utilisés



### Barème de notation des productions

| Production | Poids | Critères principaux |
|------------|-------|-------------------|
| Journal de bord LLM | 20% | Progression, réflexivité, apprentissage |
| Portfolio mini-projets | 25% | Fonctionnalité, créativité, documentation |
| Projet collaboratif | 25% | Intégration, collaboration, qualité technique |
| Rapport automatisé | 15% | Reproductibilité, robustesse, paramétrage |
| Soutenance | 15% | Maîtrise orale, démonstration live, esprit critique |

### Modalités de rendu

Support numérique : Dépôt sur plateforme pédagogique
Formats acceptés : .R, .Rmd, .PDF, .html
Deadline : Productions continues (hebdomadaires) + productions finales (fin de semestre)
Accompagnement : Consultations individuelles disponibles + feedback formatif continu

Ces productions garantissent une évaluation authentique des compétences acquises tout en constituant un véritable portfolio professionnel pour les étudiants.

Question 4

Méthodologie pour mesurer l’acquisition par les étudiant.es de la/des compétence(s) visée(s)
Méthode d'évaluation, critères, modalités.

## Méthodologie pour mesurer l'acquisition des compétences

### Compétences visées et indicateurs de maîtrise

#### Compétence 1 : Dialogue efficace avec l'IA générative

Indicateurs de maîtrise :

- Formulation de prompts précis et contextualisés
- Itération productive face aux réponses inadéquates
- Validation critique des productions de l'IA
- Intégration fluide dans un workflow d'analyse

Méthodes d'évaluation :

- Analyse du journal de bord : Évolution qualitative des prompts sur 8 séances
- Évaluation en temps réel : Observation des interactions durant les séances
- Démonstration live : Résolution d'un problème inédit en soutenance (15 min)

#### Compétence 2 : Programmation R pour l'analyse de données

Indicateurs de maîtrise :

- Code fonctionnel et robuste
- Utilisation appropriée des structures de données
- Création de fonctions personnalisées documentées
- Gestion des erreurs et cas particuliers

Méthodes d'évaluation :

- Portfolio de code : 10 fonctions minimum avec tests de validation
- Projets d'analyse : 5 mini-projets + 1 projet final collaboratif
- Code review : Évaluation croisée entre pairs avec grille standardisée

#### Compétence 3 : Pensée critique et résolution de problèmes

Indicateurs de maîtrise :

- Identification et correction d'erreurs logiques
- Décomposition de problèmes complexes
- Évaluation de la pertinence des solutions
- Adaptation face à des données inattendues

Méthodes d'évaluation :

- Exercices de debugging : Correction de codes volontairement buggés
- Projet sur données "sales" : Nettoyage et analyse de datasets problématiques
- Questions ouvertes : Justification des choix méthodologiques



### Grilles d'évaluation détaillées

#### Grille 1 : Qualité des interactions avec l'IA (sur 20 points)

| Critère | Insuffisant (0-2) | Passable (3-4) | Bien (5-6) | Excellent (7-8) | Note |
|---------|-------------------|----------------|------------|-----------------|------|
| Précision des prompts | Vagues, ambigus | Basiques mais clairs | Précis, contextualisés | Sophistiqués, anticipent les erreurs | /8 |
| Gestion des échecs | Abandonne rapidement | Reformule sans logique | Améliore systématiquement | Analyse les causes, stratégies multiples | /4 |
| Validation critique | Accepte sans vérifier | Vérifie ponctuellement | Teste systématiquement | Anticipe les cas limites | /4 |
| Intégration workflow | Copie-colle aveugle | Adaptation minimale | Intègre avec cohérence | Optimise l'ensemble du processus | /4 |

#### Grille 2 : Maîtrise technique R (sur 20 points)

| Critère | Insuffisant (0-2) | Passable (3-4) | Bien (5-6) | Excellent (7-8) | Note |
|---------|-------------------|----------------|------------|-----------------|------|
| Fonctionnalité | Code ne fonctionne pas | Fonctionne partiellement | Fonctionne correctement | Robuste, gère tous les cas | /8 |
| Organisation | Monolithique, illisible | Structure basique | Bien organisé | Modulaire, réutilisable | /4 |
| Documentation | Absente | Commentaires sporadiques | Bien commenté | Documentation complète | /4 |
| Efficacité | Approches inadaptées | Solutions basiques | Approches pertinentes | Optimisé, élégant | /4 |

#### Grille 3 : Analyse et communication (sur 20 points)

| Critère | Insuffisant (0-2) | Passable (3-4) | Bien (5-6) | Excellent (7-8) | Note |
|---------|-------------------|----------------|------------|-----------------|------|
| Interprétation | Erreurs majeures | Basique, correcte | Pertinente, nuancée | Approfondie, critique | /8 |
| Visualisation | Inadaptée | Fonctionnelle | Claire, informative | Sophistiquée, percutante | /4 |
| Communication | Confuse | Compréhensible | Claire, structurée | Engageante, professionnelle | /4 |
| Réflexivité | Absente | Superficielle | Consciente des limites | Métacognitive avancée | /4 |


### Modalités d'évaluation spécifiques

#### Évaluation continue formative (60%)

1. Journal de bord LLM (20%)
- Fréquence : Hebdomadaire
- Modalité : Auto-évaluation guidée + validation enseignant
- Critères : Progression visible, réflexivité, apprentissage des erreurs
- Outil : Rubrique standardisée avec échelle de progression

2. Mini-projets (25%)
- Fréquence : 5 projets sur 8 séances
- Modalité : Rendu individuel + présentation courte (3 min)
- Critères : Fonctionnalité, créativité, documentation
- Feedback : Retour individuel sous 48h + discussion collective

3. Participation et collaboration (15%)
- Modalité : Observation en temps réel + évaluation par les pairs
- Critères : Contribution au debugging collectif, aide aux autres, qualité des questions
- Outil : Grille d'observation + feedback 360°

#### Évaluation sommative (40%)

1. Projet collaboratif final (25%)
- Modalité : Équipes de 4, dataset commun, 4 angles d'analyse
- Évaluation : Note d'équipe (60%) + note individuelle (40%)
- Critères équipe : Intégration, cohérence, qualité collective
- Critères individuels : Contribution identifiable, maîtrise technique

2. Soutenance individuelle (15%)
- Durée : 15 minutes (5 min démo + 5 min présentation + 5 min questions)
- Modalité : Démonstration live d'interaction avec LLM + défense de portfolio
- Critères : Maîtrise orale, esprit critique, capacité d'adaptation

---

### Outils de mesure innovants

#### 1. Métriques d'interaction LLM
- Ratio succès/échec des prompts (amélioration attendue)
- Longueur moyenne des conversations (optimisation progressive)
- Types d'erreurs corrigées (évolution de la sophistication)
- Temps de résolution des problèmes (efficacité croissante)

#### 2. Analyse de la progression du code
- Complexité cyclomatique des fonctions créées
- Taux de réutilisation du code entre projets
- Couverture des cas de test dans les fonctions
- Lisibilité mesurée par des pairs

#### 3. Évaluation par les pairs structurée
- Code review croisé avec grille standardisée
- Présentation mutuelle des projets avec feedback
- Collaboration évaluée par questionnaire anonyme

---

### Dispositifs de remédiation

#### Accompagnement différencié
- Consultations individuelles pour les étudiants en difficulté
- Binômes de soutien entre étudiants de niveaux différents
- Exercices supplémentaires adaptés aux lacunes identifiées

#### Validation progressive
- Seuils de maîtrise pour chaque compétence
- Rattrapage possible sur les évaluations continues
- Adaptations pour les étudiants à besoins spécifiques

---

### Calendrier d'évaluation

| Semaine | Évaluation | Type | Poids | Feedback |
|---------|------------|------|-------|----------|
| 1-8 | Journal de bord | Continue | 20% | Hebdomadaire |
| 2,3,4,5,6 | Mini-projets | Continue | 25% | Sous 48h |
| 1-8 | Participation | Continue | 15% | Temps réel |
| 7-8 | Projet collaboratif | Sommative | 25% | Fin de projet |
| 8 | Soutenance | Sommative | 15% | Immédiat |

### Garanties de fiabilité

- Double correction pour les évaluations majeures
- Standardisation des grilles entre correcteurs
- Échantillonnage pour validation inter-juges
- Transparence des critères communiqués aux étudiants
- Traçabilité des décisions d'évaluation

Cette méthodologie garantit une évaluation authentique, progressive et différenciée des compétences visées, tout en maintenant la motivation et l'engagement des étudiants.

# Descriptif du projet

Le but de ce projet est d'apprendre à des étudiants qui n'ont *a priori* pas d'expérience de langage de programmation à coder dans le langage R grâce aux LLMs.
Les LLMs rentrent rentrent dans la vie courante et sont amenés à rester.
Ils sont à mon avis intéressant d'un point de vue pédagogique car ils permettent une forme d'apprentissage auto-didacte et ils peuvent abaisser la barrière à l'entrée pour certaines pratiques, et notamment la programmation.
L'avantage d'utiliser des LLMs comme assistant de programmation est qu'il n'y a pas de pré-requis disciplinaire.

Le but du cours est multiple :

- Apprendre aux étudiants que la programmation, c'est abordable à l'heure des LLMs et que l'on peut rapidement et assez facilement faire des choses intéressantes.
- Apprendre aux étudiants l'usage raisonnée des LLMs : ceux-ci font des erreurs et il est important d'avoir un regard critique sur leurs résultats.
Il est important ici que les LLMs fassent des erreurs.
- Il est clair que les étudiants utilisent déjà régulièrement des LLMs, mais l'expérience semble indiquer qu'ils n'ont pas un regard critique sur leur usage.
L'exemple de la programmation doit leur servir à acquérir un regard critique sur les LLMs et à questionner leurs réponses.
- Enfin, les étudiants pourront se familiariser avec quelques concepts simples de programmation et réfléchir à l'analyse de données.



## Taille des groupes

Il faut idéalement que les étudiants puissent travailler chacun sur un ordinateur en salle informatique. 
La taille des groupes est limitées par la taille des salles informatiques, qui est de l'ordre de 20 personnes en C20X.

## Public cible

Tous les niveaux de licences peuvent suivre le cours, qui n'a pas de pré-requis de discipline.
Idéalement, les étudiants devraient avoir accès à un ordinateur ou une tablette chez eux, mais ils peuvent aussi travailler dans la salle en libre service du BAPN entre les séances.
Le cours ne se destine pas aux étudiants qui ont des cours de programmation dans leur licence, dans la mesure où c'est une introduction destinée à des étudiants qui ne l'ont jamais étudié. 
A priori, cela exclus les licence de Math-info.
Son aussi exclus de l'EC libre les étudiants de licence 1 et 2 économie gestion et de licence 3 économie finance, dans la mesure où ce cours est un miroir du cours de M3P donnée en L3 économie finance.

## Semestres 

Peut être sur les deux semestre si besoin, mais d'abord au semestre 1.

## Evaluation

(voir à la fin)


#  Une première structure

## Structure de séances (5 séances de 3h)

Séance 1 : Premiers pas et variables

Objectif de la séance : Se familiariser avec l'utilisation d'un LLM pour programmer avec R.
Acquérir le concept de variable

Activités : d'abord 1h de présentation suivi de 2h de travail sur machine pour faire les premières manipulations.

- Introduction aux LLM et R/RStudio
- Concept de variable et assignation
- Types de données (numérique, texte, logique)
- Premiers calculs et manipulations

Séance 2 : Vecteurs et premières fonctions

Objectif de la séance : Introduction de la notion de fonction. Progresser dans la programmation, commencer à utiliser des fonctions R intégrées.

Activités : d'abord 1h de présentation suivi de 2h de travail sur machine pour faire les premières manipulations.

- Création et manipulation de vecteurs
- Introduction aux fonctions built-in (`mean()`, `sum()`, `length()`)
- Lecture de données simples
- Statistiques descriptives de base

Séance 3 : Fonctions personnalisées et contrôle

Objectif de la séance : Progresser dans le codage, apprendre à créer ses propres fonctions pour un usage avancé de R.
Apprendre à utiliser des conditions.

Activités : d'abord 1h de présentation suivi de 2h de travail sur machine pour faire les premières manipulations.

- Écrire ses propres fonctions simples
- Structures conditionnelles (`if/else`)
- Boucles simples (`for`)
- Application sur des cas concrets d'analyse

Séance 4 : Dataframes et visualisation

Objectif de la séance : Introduction aux notions de données et à leur représentation. 
Introduction de l'usage des fonctions sur des tableaux de données.

Activités : d'abord 1h de présentation suivi de 2h de travail sur machine pour faire les premières manipulations.

- Manipulation de tableaux de données
- Fonctions d'agrégation (`group_by`, `summarise`)
- Graphiques avec ggplot2
- Fonctions pour automatiser les graphiques

Séance 5 : Projet intégré

Objectifs : Analyser des données en autonomie.

Activités : 1h de présentation suivi de 2h de travail sur machine pour réaliser le projet.

- Analyse complète d'un jeu de données
- Création de fonctions personnalisées pour l'analyse
- Présentation des résultats


Séance 6 : Programmation modulaires et librairies

Objectifs :

- Comprendre l'organisation du code en modules
- Découvrir l'écosystème des librairies R
- Apprendre à lire et utiliser la documentation

Activités : 1h de présentation suivi de 2h de travail sur machine pour découvrir les notions abordées

Séance 7 : Introduction au markdown et à la reproductibilité

Objectifs : 

- Automatiser des tâches répétitives
- Créer des rapport reproductibles
- Introduction au markdown

Activités : Présentation suidi d'un travail de mise en pratique sur machine.

Séance 8 : Collaboration

Objectifs : Apprendre les bonnes pratiques pour travailler en collaboration sur du code

Activités : travail en groupe pour résoudre un problème complexe.

## Progression pédagogique des 8 séances

### Arc narratif complet 

1. Séances 1-2 : Bases individuelles
2. Séances 3-4 : Autonomie technique  
3. Séances 5-6 : Projets personnels et modularité
4. Séances 7-8 : Automatisation et collaboration

### Évolution des compétences LLM 

- Début : Prompts simples et correction d'erreurs
- Milieu : Prompts complexes et validation critique
- Fin : Prompts stratégiques et intégration workflow

### Montée en complexité des erreurs :

Séance 6 - Erreurs d'architecture :
```
"Organise mon code en modules logiques"
# Le LLM peut proposer une architecture inadaptée
```

Séance 7 - Erreurs de performance :
```
"Traite 1000 fichiers CSV avec une boucle"
# Le LLM peut proposer du code très lent
```

Séance 8 - Erreurs de collaboration :
```r
# Conflits de nommage entre équipes
equipe1_calcul_moyenne <- function(x) {...}
equipe2_moyenne <- function(data) {...}
# Même fonction, signatures différentes !
```



Travail à la maison

Les étudiants auront aussi entre chaque séances des exercices à faire, afin de compléter leur  apprentissage.

## Stratégies pour provoquer des erreurs utiles

Prompts ambigus volontairement :

- "Fais-moi un graphique de mes données" (sans préciser le type)
- "Calcule la moyenne" (sans préciser de quelle variable)
- "Groupe mes données par catégorie" (variables mal définies)

Situations génératrices d'erreurs :

- Données manquantes : Utiliser des jeux de données avec des `NA`
- Types de variables : Mélanger texte et nombres
- Noms de colonnes : Utiliser des espaces ou caractères spéciaux
- Packages non chargés : Demander du ggplot2 sans `library()`

Exercices "piégés" :

```r
# Exemple de prompt problématique
"Crée une fonction qui calcule la moyenne d'une liste de nombres"
# Le LLM risque d'oublier les NA ou la validation des inputs
```

Techniques pédagogiques pour exploiter les erreurs :

1. "Debugging collectif" : Projeter le code qui plante et chercher ensemble
2. "Amélioration itérative" : Faire évoluer un prompt pour corriger progressivement
3. "Validation croisée" : Comparer les réponses de différents étudiants au même prompt

Progression des concepts de programmation :

- Séance 1 : Variable = boîte qui contient une valeur
- Séance 2 : Fonction = machine qui transforme des inputs en outputs
- Séance 3 : Fonction personnalisée = créer sa propre machine
- Séance 4 : Fonctions sur tableaux = traiter plusieurs données à la fois
- Séance 5 : Orchestrer plusieurs fonctions pour résoudre un problème

Exemples de prompts "éducativement défaillants" :

- "Analyse ce fichier CSV" (trop vague)
- "Fais un beau graphique" (critères esthétiques flous)
- "Cette fonction ne marche pas" (sans montrer le code)

Cette approche permet d'apprendre à la fois la programmation ET l'utilisation efficace des LLM.

### Évaluation des séances avancées :

Séance 6 : Portfolio de fonctions documentées
Séance 7 : Rapport automatisé fonctionnel  
Séance 8 : Contribution au projet collaboratif + code review

## Exemples détaillés par séance

### Séance 1 : Premiers pas et variables

Exercice d'ouverture - Le piège du prompt vague :

```
Prompt volontairement problématique : "Fais-moi des calculs en R"
```

Le LLM va probablement donner des exemples génériques. Les étudiants découvrent qu'il faut être précis.

Meilleur prompt :

```
"Je veux calculer l'âge moyen d'un groupe de personnes : 25, 30, 45, 22, 38 ans. 
Écris le code R et explique chaque ligne."
```

Exercice piégé - Types de données :

```r
# Code que le LLM pourrait proposer
ages <- c("25", "30", "45", "22", "38")  # Piège : guillemets !
moyenne <- mean(ages)
```

Erreur garantie ! Discussion sur les types de données.


### Séance 2 : Vecteurs et premières fonctions

Jeu de données simple avec pièges :

```r
# Données météo avec des NA cachés
temperatures <- c(15, 18, NA, 22, 16, NA, 20)
precipitations <- c(0, 5, 2, 0, 8, 1, 3)
```

Prompt piégé :

```
"Calcule la température moyenne de ces données météo"
```

Le LLM peut oublier `na.rm = TRUE`, erreur pédagogique parfaite !

Exercice fonction personnalisée :

```
"Crée une fonction qui me dit s'il fait beau (temp > 20 et pas de pluie)"
```


### Séance 3 : Fonctions personnalisées et contrôle

Exercice - Fonction de notation :

```
Prompt : "Crée une fonction qui convertit une note sur 20 en mention : 
- < 10 : Insuffisant
- 10-12 : Passable  
- 12-14 : Assez bien
- 14-16 : Bien
- > 16 : Très bien"
```

Piège classique - traitement des cas limites :

```r
# Code problématique du LLM
convertir_note <- function(note) {
  if (note < 10) return("Insuffisant")
  if (note < 12) return("Passable")
  # Qu'est-ce qui se passe si note = 12 exactement ?
}
```

Exercice debugging :

```r
# Code volontairement buggé à corriger
calculer_moyenne_classe <- function(notes) {
  total <- 0
  for (i in 1:length(notes)) {
    total <- total + note[i]  # Erreur : 'note' au lieu de 'notes'
  }
  return(total / length(notes))
}
```


### Séance 4 : Dataframes et visualisation

Jeu de données réaliste avec pièges :

```r
# Données ventes avec problèmes volontaires
ventes <- data.frame(
  mois = c("Jan", "Fév", "Mar", "Avr", "Mai", "Jun"),
  montant = c(1500, 2000, NA, 1800, 2200, 1900),
  vendeur = c("Alice", "Bob", "alice", "Bob", "Alice", "bob")  # Casse incohérente !
)
```

Prompts piégés :

```
1. "Fais un graphique de l'évolution des ventes"
   # Problème : mois en texte, ordre alphabétique au lieu de chronologique

2. "Calcule les ventes par vendeur" 
   # Problème : Alice/alice et Bob/bob comptés séparément

3. "Crée une fonction qui fait un beau graphique"
   # Trop vague, le LLM va improviser
```

Exercice fonction graphique :

```r
# Demander une fonction qui génère un graphique standard
creer_graphique_ventes <- function(donnees, titre = "Ventes") {
  # Le LLM oubliera souvent les paramètres par défaut
  # ou la gestion des colonnes manquantes
}
```


### Séance 5 : Projet intégré

Dataset complexe avec multiples pièges :

```r
# Données étudiants avec tous les problèmes possibles
etudiants <- data.frame(
  nom = c("Dupont", "Martin", "Durand", "", "Petit"),
  age = c(20, "vingt-deux", 19, 21, 18),  # Type mixte
  note_math = c(15, 12, NA, 16, 14),
  note_info = c(13, NA, 15, 12, 16),
  filiere = c("Info", "info", "Maths", "INFO", "maths")  # Casse incohérente
)
```

Mission complexe :

```
"Analyse complète : moyennes par filière, graphique des résultats, 
fonction qui attribue les mentions, rapport final"
```

Erreurs attendues et apprentissages :

1. Nettoyage des données oublié
2. Gestion des NA dans les calculs
3. Standardisation des noms de filières
4. Validation des types de données


### Séance 6 : Programmation modulaire et packages

Objectifs :

- Comprendre l'organisation du code en modules
- Découvrir l'écosystème des packages R
- Apprendre à lire et utiliser la documentation

Contenu :

- Scripts vs fonctions vs packages : Organisation hiérarchique du code
- Exploration de packages : dplyr, lubridate, stringr
- Sourcing de scripts : `source()` et organisation des fichiers
- Gestion des dépendances : `library()` vs `require()`

Exercices piégés :

```r
# Prompt problématique
"Utilise le package tidyverse pour analyser mes données"
# Problème : package pas installé, functions en conflit

# Dataset avec dates problématiques
donnees_temporelles <- data.frame(
  date = c("2023-01-15", "15/02/2023", "March 3, 2023", "2023-4-1"),
  ventes = c(100, 150, 200, 175)
)
```

Mission complexe :

"Crée un 'mini-package' (dossier avec plusieurs scripts) pour analyser des données de vente avec des fonctions spécialisées : nettoyage, analyse, visualisation"

Erreurs attendues :

- Fonctions qui se chevauchent entre scripts
- Packages manquants ou conflictuels
- Gestion incorrecte des chemins de fichiers



### Séance 7 : Automatisation et rapports

Objectifs :

- Automatiser des tâches répétitives
- Créer des rapports reproductibles
- Introduction à R Markdown

Contenu :

- Boucles avancées : `apply()`, `lapply()`, `map()`
- Traitement par lots : analyser plusieurs fichiers d'un coup
- R Markdown : mélanger code et texte
- Paramètres de rapport : rendre les analyses flexibles

Exercices piégés :

```r
# Plusieurs fichiers CSV avec structures différentes
fichiers <- c("ventes_2023.csv", "ventes_2024.csv", "ventes_Q1.csv")
# Prompt piégé : "Analyse tous ces fichiers en même temps"
# Problèmes : colonnes différentes, formats de dates variables
```

Mission complexe :

"Crée un rapport automatisé qui analyse n'importe quel fichier de ventes et génère un PDF avec graphiques et recommandations"

Erreurs typiques :

- Boucles infinies ou inefficaces
- Chemins de fichiers hardcodés
- Rapports qui plantent sur données inattendues
- Oubli de la gestion des cas vides



### Séance 8 : Projet collaboratif et bonnes pratiques

Objectifs :

- Travailler en équipe sur du code
- Intégrer les bonnes pratiques de développement
- Gérer un projet de A à Z

Contenu :

- Conventions de nommage et style de code
- Tests unitaires simples avec `testthat`
- Gestion d'erreurs : `try()`, `tryCatch()`
- Documentation : commenter pour les autres
- Projet collaboratif : analyse croisée de données

Projet final collaboratif :

Équipes de 3-4 étudiants analysent le même grand dataset (ex: données COVID, élections, climat) sous différents angles :
- Équipe 1 : Analyse temporelle
- Équipe 2 : Analyse géographique  
- Équipe 3 : Analyse comparative
- Équipe 4 : Prédictions simples

Exercices piégés :

```r
# Code volontairement mal écrit à refactoriser
a<-function(x,y,z){
  r<-0
  for(i in 1:100){
    if(x[i]>y&!is.na(z[i])){r<-r+x[i]*z[i]}
  }
  return(r)
}
# Mission : "Améliore ce code et explique ce qu'il fait"
```

Défis spécifiques :

- Code legacy : comprendre et améliorer du code mal écrit
- Intégration : faire fonctionner ensemble le code de différentes équipes
- Validation croisée : vérifier les résultats des autres équipes
- Documentation : expliquer son travail aux autres



### Compétences finales acquises :
- Techniques : R intermédiaire, organisation du code, automatisation
- Méthodologiques : Debugging, documentation, tests
- Collaboratives : Travail en équipe, code review
- IA : Prompting avancé, validation critique, intégration workflow

Cette progression de 8 séances forme un parcours complet de l'initiation à l'autonomie en programmation R assistée par IA. Les étudiants sortent avec une vraie compétence professionnelle. Voulez-vous que je détaille certains exercices ou que je propose des datasets spécifiques pour ces séances avancées ?


## Stratégies pédagogiques pour exploiter les erreurs

1. La méthode "Code Cassé" :

- Projeter un code avec erreur
- "Qui voit le problème ?"
- Discussion collective avant correction

2. Le "Prompt Battle" :

- Diviser la classe en équipes
- Même objectif, prompts différents
- Comparer les résultats et erreurs

3. Le "Debugging Live" :

- Écrire volontairement un mauvais prompt
- Améliorer itérativement avec la classe
- Montrer l'évolution de la qualité du code

4. L'exercice "Validation" :

- Le LLM propose du code
- Les étudiants doivent prédire s'il va marcher
- Exécution pour vérifier

Ces exercices garantissent des erreurs instructives tout en enseignant les concepts de programmation essentiels.

## Evaluation

### Évaluation tout au long des séances

#### Évaluation formative continue (60% de la note finale)

1. Journal de bord des interactions LLM (20%)

- Carnet de prompts et réponses avec réflexions
- Évolution de la qualité des questions posées
- Documentation des erreurs rencontrées et solutions trouvées

*Exemple de grille* :

- Clarté des prompts (0-4 pts)
- Capacité à corriger les erreurs (0-4 pts) 
- Réflexion sur les réponses du LLM (0-4 pts)
- Progression visible (0-4 pts)

2. Mini-projets hebdomadaires (25%)

- Analyse de petits jeux de données
- Code commenté + interprétation des résultats
- Évaluation par les pairs en binômes

*Séance 1* : Analyser des données météo de leur ville  
*Séance 2* : Créer 3 fonctions utiles avec documentation  
*Séance 3* : Nettoyer un dataset "sale" fourni  
*Séance 4* : Dashboard simple avec 3 graphiques différents  

3. Participation et debugging collectif (15%)

- Contribution aux discussions d'erreurs
- Aide apportée aux autres étudiants
- Qualité des questions posées en cours

#### Évaluation sommative finale (40%)

Option 1 : Examen pratique sur ordinateur (2h)

Partie A - Analyse guidée (15 pts) :
Jeu de données fourni avec consignes précises :

```
Dataset : Résultats sportifs avec erreurs volontaires
Tâches :
1. Nettoyer les données (5 pts)
2. Calculer 5 statistiques demandées (5 pts)  
3. Créer 2 graphiques spécifiés (5 pts)
```

Partie B - Résolution de problèmes (5 pts) :
Codes R avec erreurs à identifier et corriger :

```r
# Exemple d'exercice
ma_fonction <- function(x) {
  resultat <- 0
  for (i in 1:lenght(x)) {  # Erreur volontaire
    if (x[i] > 10)
      resultat <- resultat + x[i]
  }
  return(resultat)
```

Option 2 : Projet final + soutenance

Projet (30 pts) :

- Analyse complète d'un dataset au choix
- Minimum 3 fonctions personnalisées
- Rapport de 3 pages + code commenté
- Dossier de prompts utilisés avec réflexions

Soutenance (10 pts - 10 min/étudiant) :

- Présentation des résultats (5 pts)
- Démonstration live d'une interaction avec LLM (3 pts)
- Questions/réponses sur le code produit (2 pts)

### Grilles d'évaluation spécifiques

Qualité du code (sur toutes évaluations) :

- Fonctionnalité : Le code fait ce qui est demandé (0-4)
- Lisibilité : Noms de variables, commentaires (0-4)  
- Robustesse : Gestion des cas particuliers (0-4)
- Efficacité : Utilisation appropriée des fonctions R (0-4)

Interaction avec les LLM :

- Prompts : Précision et clarté des demandes (0-4)
- Validation : Vérification des réponses obtenues (0-4)
- Itération : Amélioration progressive des prompts (0-4)
- Esprit critique : Identification des limites/erreurs (0-4)

### Alternative : Outils d'évaluation innovants

1. "Prompt Challenge" (évaluation flash - 5 min) :
Problème donné → Qui écrit le meilleur prompt pour le résoudre ?
2. "Code Review" :
Les étudiants commentent le code d'un pair produit avec LLM
3. "Error Hunt" :
Code avec 5 erreurs cachées, noter celles trouvées en 15 min
4. Auto-évaluation réflexive :
"Qu'avez-vous appris cette séance ? Quelles difficultés ?"

### Adaptations selon le niveau ?

Pour les plus faibles :

- QCM sur les concepts de base
- Exercices guidés étape par étape
- Évaluation sur la progression plutôt que le niveau absolu

Pour les plus avancés :

- Défis supplémentaires (optimisation, packages avancés)
- Mentorat des autres étudiants (bonus)
- Projet libre avec contraintes techniques

Cette approche évalue à la fois la maîtrise technique ET la capacité à utiliser efficacement les LLM, compétence clé pour l'avenir.
